import json
import re
from selenium.webdriver.common.by import By
from xml.etree.ElementTree import Element, SubElement, tostring
from xml.dom import minidom
import os
from datetime import datetime
import requests

class NaraParser:
    """ë‚˜ë¼ì¥í„° API íŒŒì„œ í´ë˜ìŠ¤"""
    
    def __init__(self, driver):
        self.driver = driver
    
    def extract_table_info(self):
        """í…Œì´ë¸” ì •ë³´ ì¶”ì¶œ - ìµœìš°ì„  ì‹¤í–‰"""
        try:
            table_info = {}
            print("ğŸ” í…Œì´ë¸” ê²€ìƒ‰ ì¤‘...")
            
            # ëª¨ë“  í…Œì´ë¸” ì°¾ê¸°
            tables = self.driver.find_elements(By.CSS_SELECTOR, "table.dataset-table")
            print(f"ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}")
            
            for idx, table in enumerate(tables, 1):
                print(f"ğŸ“‹ í…Œì´ë¸” {idx} ì²˜ë¦¬ ì¤‘...")
                
                # í…Œì´ë¸” ë‚´ìš© ì¶”ì¶œ
                rows = table.find_elements(By.TAG_NAME, "tr")
                
                for row in rows:
                    try:
                        # thì™€ td íƒœê·¸ ì°¾ê¸°
                        th = row.find_element(By.TAG_NAME, "th")
                        td = row.find_element(By.TAG_NAME, "td")
                        
                        key = th.text.strip()
                        value = td.text.strip()
                        
                        # ì „í™”ë²ˆí˜¸ì˜ ê²½ìš° JavaScriptë¡œ ì²˜ë¦¬ëœ ê°’ì„ ê°€ì ¸ì˜¤ê¸°
                        if "ì „í™”ë²ˆí˜¸" in key:
                            try:
                                tel_no_div = td.find_element(By.ID, "telNoDiv")
                                value = tel_no_div.text.strip()
                            except:
                                pass
                        
                        # ë§í¬ê°€ ìˆëŠ” ê²½ìš° ë§í¬ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                        if not value:
                            try:
                                link = td.find_element(By.TAG_NAME, "a")
                                value = link.text.strip()
                            except:
                                pass
                        
                        if key and value:
                            table_info[key] = value
                            print(f"  - {key}: {value}")
                    except Exception as e:
                        print(f"  âš ï¸ í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        continue
            
            print(f"ğŸ“Š ì´ {len(table_info)}ê°œì˜ í•­ëª© ì¶”ì¶œ ì™„ë£Œ")
            
            # API ìœ í˜• í™•ì¸ ë° ë¡œê¹…
            api_type = table_info.get('API ìœ í˜•', '')
            if api_type:
                print(f"ğŸ” ê°ì§€ëœ API ìœ í˜•: {api_type}")
                if 'LINK' in api_type.upper():
                    print("ğŸ”— LINK íƒ€ì… API ê°ì§€ - ì¶”ê°€ í¬ë¡¤ë§ ê±´ë„ˆë›¸ ì˜ˆì •")
            
            return table_info
            
        except Exception as e:
            print(f"âŒ í…Œì´ë¸” ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def extract_swagger_json(self):
        """Swagger JSON ì¶”ì¶œ - ê°œì„ ëœ ë¡œì§"""
        try:
            print("ğŸ” Swagger JSON ì¶”ì¶œ ì‹œë„...")
            
            # 1. JavaScript ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
            swagger_json = self.driver.execute_script("""
                try {
                    if (typeof swaggerJson !== 'undefined' && swaggerJson !== null) {
                        console.log('swaggerJson ë³€ìˆ˜ ë°œê²¬:', typeof swaggerJson);
                        if (typeof swaggerJson === 'string') {
                            if (swaggerJson.trim() === '') {
                                console.log('swaggerJsonì€ ë¹ˆ ë¬¸ìì—´ì…ë‹ˆë‹¤.');
                                return null;
                            }
                            return JSON.parse(swaggerJson);
                        } else if (typeof swaggerJson === 'object') {
                            return swaggerJson;
                        }
                    }
                    return null;
                } catch (e) {
                    console.log('swaggerJson ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜:', e);
                    return null;
                }
            """)
            
            if swagger_json and isinstance(swagger_json, dict) and swagger_json:
                print("âœ… JavaScript ë³€ìˆ˜ì—ì„œ Swagger JSON ì¶”ì¶œ ì„±ê³µ!")
                return swagger_json
            
            # 2. script íƒœê·¸ì—ì„œ swaggerJson ë³€ìˆ˜ ì¶”ì¶œ ì‹œë„
            print("ğŸ” Script íƒœê·¸ì—ì„œ swaggerJson ì¶”ì¶œ ì‹œë„...")
            scripts = self.driver.find_elements(By.TAG_NAME, "script")
            for script in scripts:
                script_content = script.get_attribute("innerHTML")
                if script_content and 'swaggerJson' in script_content:
                    print("ğŸ“ swaggerJsonì´ í¬í•¨ëœ ìŠ¤í¬ë¦½íŠ¸ ë°œê²¬")
                    
                    # ë¹ˆ swaggerJson íŒ¨í„´ ë¨¼ì € í™•ì¸
                    empty_patterns = [
                        r'var\s+swaggerJson\s*=\s*[\'\"]\s*[\'\"]\s*[;,]',
                        r'swaggerJson\s*=\s*[\'\"]\s*[\'\"]\s*[;,]',
                        r'var\s+swaggerJson\s*=\s*`\s*`\s*[;,]',
                        r'swaggerJson\s*=\s*`\s*`\s*[;,]'
                    ]
                    
                    for pattern in empty_patterns:
                        if re.search(pattern, script_content):
                            print("ğŸ” swaggerJsonì´ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •ë¨ - ì¼ë°˜ API ëª¨ë“œë¡œ ì „í™˜")
                            return None
                    
                    # swaggerJson ê°’ ì¶”ì¶œ íŒ¨í„´ë“¤
                    json_patterns = [
                        r'var\s+swaggerJson\s*=\s*(\{.*?\})\s*[;,]',  # var swaggerJson = {...};
                        r'swaggerJson\s*=\s*(\{.*?\})\s*[;,]',        # swaggerJson = {...};
                        r'swaggerJson\s*:\s*(\{.*?\})',               # swaggerJson: {...}
                        r'var\s+swaggerJson\s*=\s*`(\{.*?\})`',       # var swaggerJson = `{...}`;
                        r'swaggerJson\s*=\s*`(\{.*?\})`'              # swaggerJson = `{...}`;
                    ]
                    
                    for pattern in json_patterns:
                        json_match = re.search(pattern, script_content, re.DOTALL)
                        if json_match:
                            try:
                                json_str = json_match.group(1)
                                # JSON ë¬¸ìì—´ ì •ë¦¬
                                json_str = json_str.replace('\n', '').replace('\r', '')
                                parsed_json = json.loads(json_str)
                                if parsed_json:  # ë¹ˆ ê°ì²´ê°€ ì•„ë‹Œ ê²½ìš°
                                    print("âœ… Script íƒœê·¸ì—ì„œ Swagger JSON ì¶”ì¶œ ì„±ê³µ!")
                                    return parsed_json
                            except Exception as e:
                                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                                continue
            
            # 3. window.swaggerUi ë³€ìˆ˜ì—ì„œ ì¶”ì¶œ ì‹œë„
            print("ğŸ” window.swaggerUiì—ì„œ ì¶”ì¶œ ì‹œë„...")
            swagger_json = self.driver.execute_script("""
                try {
                    if (window.swaggerUi && window.swaggerUi.spec) {
                        return window.swaggerUi.spec;
                    }
                    return null;
                } catch (e) {
                    return null;
                }
            """)
            
            if swagger_json and isinstance(swagger_json, dict) and swagger_json:
                print("âœ… window.swaggerUiì—ì„œ Swagger JSON ì¶”ì¶œ ì„±ê³µ!")
                return swagger_json
            
            # 4. Swagger UI ì´ˆê¸°í™” ì½”ë“œì—ì„œ URL ì¶”ì¶œ ì‹œë„
            print("ğŸ” Swagger UI ì´ˆê¸°í™” ì½”ë“œì—ì„œ URL ì¶”ì¶œ ì‹œë„...")
            for script in scripts:
                script_content = script.get_attribute("innerHTML")
                if script_content and 'SwaggerUIBundle' in script_content:
                    # URL íŒ¨í„´ ì°¾ê¸°
                    url_match = re.search(r'url\s*:\s*[\'"]([^\'"]+)[\'"]', script_content)
                    if url_match:
                        swagger_url = url_match.group(1)
                        if swagger_url.startswith('/'):
                            current_url = self.driver.current_url
                            base_url = '/'.join(current_url.split('/')[:3])
                            swagger_url = base_url + swagger_url
                        
                        try:
                            print(f"ğŸŒ ì™¸ë¶€ Swagger URL ìš”ì²­: {swagger_url}")
                            response = requests.get(swagger_url, timeout=10)
                            if response.status_code == 200:
                                swagger_data = response.json()
                                if swagger_data:
                                    print("âœ… ì™¸ë¶€ URLì—ì„œ Swagger JSON ì¶”ì¶œ ì„±ê³µ!")
                                    return swagger_data
                        except Exception as e:
                            print(f"âš ï¸ ì™¸ë¶€ URL ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
                    
                    # ì¸ë¼ì¸ spec ê°ì²´ ì°¾ê¸°
                    spec_match = re.search(r'spec\s*:\s*(\{.*?\})\s*[,}]', script_content, re.DOTALL)
                    if spec_match:
                        try:
                            spec_str = spec_match.group(1)
                            spec_json = json.loads(spec_str)
                            if spec_json:
                                print("âœ… ì¸ë¼ì¸ specì—ì„œ Swagger JSON ì¶”ì¶œ ì„±ê³µ!")
                                return spec_json
                        except Exception as e:
                            print(f"âš ï¸ ì¸ë¼ì¸ spec íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            
            print("âŒ Swagger JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        except Exception as e:
            print(f"âŒ Swagger JSON ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def extract_general_api_info(self):
        """ì¼ë°˜ API ì •ë³´ ì¶”ì¶œ (Swaggerê°€ ì—†ëŠ” ê²½ìš°)"""
        try:
            general_info = {}
            print("ğŸ” ì¼ë°˜ API ì •ë³´ ì¶”ì¶œ ì¤‘...")
            
            # 1. ìƒì„¸ê¸°ëŠ¥ ì •ë³´ ì¶”ì¶œ
            print("ğŸ“‹ ìƒì„¸ê¸°ëŠ¥ ì •ë³´ ì¶”ì¶œ ì¤‘...")
            detail_info = self._extract_detail_info()
            if detail_info:
                general_info['detail_info'] = detail_info
                print(f"âœ… ìƒì„¸ê¸°ëŠ¥ ì •ë³´ ì¶”ì¶œ: {len(detail_info)}ê°œ í•­ëª©")
            
            # 2. ìš”ì²­ë³€ìˆ˜(Request Parameter) ì¶”ì¶œ
            print("ğŸ“¤ ìš”ì²­ë³€ìˆ˜ ì¶”ì¶œ ì¤‘...")
            request_params = self._extract_request_parameters()
            if request_params:
                general_info['request_parameters'] = request_params
                print(f"âœ… ìš”ì²­ë³€ìˆ˜ ì¶”ì¶œ: {len(request_params)}ê°œ íŒŒë¼ë¯¸í„°")
            
            # 3. ì¶œë ¥ê²°ê³¼(Response Element) ì¶”ì¶œ
            print("ğŸ“¥ ì¶œë ¥ê²°ê³¼ ì¶”ì¶œ ì¤‘...")
            response_elements = self._extract_response_elements()
            if response_elements:
                general_info['response_elements'] = response_elements
                print(f"âœ… ì¶œë ¥ê²°ê³¼ ì¶”ì¶œ: {len(response_elements)}ê°œ ìš”ì†Œ")
            
            return general_info
            
        except Exception as e:
            print(f"âŒ ì¼ë°˜ API ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _extract_detail_info(self):
        """ìƒì„¸ê¸°ëŠ¥ ì •ë³´ ì¶”ì¶œ"""
        try:
            detail_info = {}
            
            # open-api-detail-result div ì°¾ê¸°
            detail_div = self.driver.find_element(By.ID, "open-api-detail-result")
            
            # h4.tit ë‚´ìš© ì¶”ì¶œ (API ì„¤ëª…)
            try:
                title_elem = detail_div.find_element(By.CSS_SELECTOR, "h4.tit")
                detail_info['description'] = title_elem.text.strip()
            except:
                detail_info['description'] = ""
            
            # box-gray í•˜ìœ„ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            try:
                box_gray = detail_div.find_element(By.CLASS_NAME, "box-gray")
                list_items = box_gray.find_elements(By.CSS_SELECTOR, "ul.dot-list li")
                
                for item in list_items:
                    item_text = item.text.strip()
                    
                    # í™œìš©ìŠ¹ì¸ ì ˆì°¨
                    if "í™œìš©ìŠ¹ì¸ ì ˆì°¨" in item_text:
                        # ê°œë°œë‹¨ê³„ì™€ ìš´ì˜ë‹¨ê³„ ì •ë³´ ì¶”ì¶œ
                        dev_match = re.search(r'ê°œë°œë‹¨ê³„\s*:\s*([^/]+)', item_text)
                        op_match = re.search(r'ìš´ì˜ë‹¨ê³„\s*:\s*(.+)', item_text)
                        
                        approval_process = {}
                        if dev_match:
                            approval_process['development'] = dev_match.group(1).strip()
                        if op_match:
                            approval_process['operation'] = op_match.group(1).strip()
                        
                        detail_info['approval_process'] = approval_process
                    
                    # ì‹ ì²­ê°€ëŠ¥ íŠ¸ë˜í”½
                    elif "ì‹ ì²­ê°€ëŠ¥ íŠ¸ë˜í”½" in item_text:
                        # ê°œë°œê³„ì •ê³¼ ìš´ì˜ê³„ì • ì •ë³´ ì¶”ì¶œ
                        dev_traffic_match = re.search(r'ê°œë°œê³„ì •\s*:\s*([^/]+)', item_text)
                        op_traffic_match = re.search(r'ìš´ì˜ê³„ì •\s*:\s*(.+)', item_text)
                        
                        traffic_info = {}
                        if dev_traffic_match:
                            traffic_info['development'] = dev_traffic_match.group(1).strip()
                        if op_traffic_match:
                            traffic_info['operation'] = op_traffic_match.group(1).strip()
                        
                        detail_info['traffic_limit'] = traffic_info
                    
                    # ìš”ì²­ì£¼ì†Œ
                    elif "ìš”ì²­ì£¼ì†Œ" in item_text:
                        url_match = re.search(r'ìš”ì²­ì£¼ì†Œ\s*(.+)', item_text)
                        if url_match:
                            detail_info['request_url'] = url_match.group(1).strip()
                    
                    # ì„œë¹„ìŠ¤URL
                    elif "ì„œë¹„ìŠ¤URL" in item_text:
                        service_url_match = re.search(r'ì„œë¹„ìŠ¤URL\s*(.+)', item_text)
                        if service_url_match:
                            detail_info['service_url'] = service_url_match.group(1).strip()
            except Exception as e:
                print(f"âš ï¸ box-gray ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            return detail_info
            
        except Exception as e:
            print(f"âš ï¸ ìƒì„¸ê¸°ëŠ¥ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _extract_request_parameters(self):
        """ìš”ì²­ë³€ìˆ˜(Request Parameter) í…Œì´ë¸” ì¶”ì¶œ"""
        try:
            parameters = []
            
            # ìš”ì²­ë³€ìˆ˜ ì„¹ì…˜ ì°¾ê¸°
            headers = self.driver.find_elements(By.CSS_SELECTOR, "h4.tit")
            request_header = None
            
            for header in headers:
                if "ìš”ì²­ë³€ìˆ˜" in header.text and "Request Parameter" in header.text:
                    request_header = header
                    break
            
            if not request_header:
                print("âš ï¸ ìš”ì²­ë³€ìˆ˜ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return parameters
            
            # ìš”ì²­ë³€ìˆ˜ í…Œì´ë¸” ì°¾ê¸° (í—¤ë” ë‹¤ìŒ div.col-table)
            table_div = request_header.find_element(By.XPATH, "following-sibling::div[contains(@class, 'col-table')]")
            table = table_div.find_element(By.TAG_NAME, "table")
            
            # í…Œì´ë¸” í–‰ ì¶”ì¶œ (í—¤ë” ì œì™¸)
            tbody = table.find_element(By.TAG_NAME, "tbody")
            rows = tbody.find_elements(By.TAG_NAME, "tr")
            
            for row in rows:
                try:
                    cells = row.find_elements(By.TAG_NAME, "td")
                    if len(cells) >= 6:  # ìµœì†Œ 6ê°œ ì—´ì´ ìˆì–´ì•¼ í•¨
                        parameter = {
                            'name_kor': cells[0].text.strip(),          # í•­ëª©ëª…(êµ­ë¬¸)
                            'name_eng': cells[1].text.strip(),          # í•­ëª©ëª…(ì˜ë¬¸)
                            'size': cells[2].text.strip(),              # í•­ëª©í¬ê¸°
                            'required': cells[3].text.strip(),          # í•­ëª©êµ¬ë¶„ (í•„/ì˜µ)
                            'sample_data': cells[4].text.strip(),       # ìƒ˜í”Œë°ì´í„°
                            'description': cells[5].text.strip()        # í•­ëª©ì„¤ëª…
                        }
                        
                        # ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                        if parameter['name_eng'] or parameter['name_kor']:
                            parameters.append(parameter)
                            
                except Exception as e:
                    print(f"âš ï¸ íŒŒë¼ë¯¸í„° í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue
            
            return parameters
            
        except Exception as e:
            print(f"âš ï¸ ìš”ì²­ë³€ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _extract_response_elements(self):
        """ì¶œë ¥ê²°ê³¼(Response Element) í…Œì´ë¸” ì¶”ì¶œ"""
        try:
            elements = []
            
            # ì¶œë ¥ê²°ê³¼ ì„¹ì…˜ ì°¾ê¸°
            headers = self.driver.find_elements(By.CSS_SELECTOR, "h4.tit")
            response_header = None
            
            for header in headers:
                if "ì¶œë ¥ê²°ê³¼" in header.text and "Response Element" in header.text:
                    response_header = header
                    break
            
            if not response_header:
                print("âš ï¸ ì¶œë ¥ê²°ê³¼ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return elements
            
            # ì¶œë ¥ê²°ê³¼ í…Œì´ë¸” ì°¾ê¸° (í—¤ë” ë‹¤ìŒ div.col-table)
            table_div = response_header.find_element(By.XPATH, "following-sibling::div[contains(@class, 'col-table')]")
            table = table_div.find_element(By.TAG_NAME, "table")
            
            # í…Œì´ë¸” í–‰ ì¶”ì¶œ (í—¤ë” ì œì™¸)
            tbody = table.find_element(By.TAG_NAME, "tbody")
            rows = tbody.find_elements(By.TAG_NAME, "tr")
            
            for row in rows:
                try:
                    cells = row.find_elements(By.TAG_NAME, "td")
                    if len(cells) >= 6:  # ìµœì†Œ 6ê°œ ì—´ì´ ìˆì–´ì•¼ í•¨
                        element = {
                            'name_kor': cells[0].text.strip(),          # í•­ëª©ëª…(êµ­ë¬¸)
                            'name_eng': cells[1].text.strip(),          # í•­ëª©ëª…(ì˜ë¬¸)
                            'size': cells[2].text.strip(),              # í•­ëª©í¬ê¸°
                            'required': cells[3].text.strip(),          # í•­ëª©êµ¬ë¶„ (í•„/ì˜µ)
                            'sample_data': cells[4].text.strip(),       # ìƒ˜í”Œë°ì´í„°
                            'description': cells[5].text.strip()        # í•­ëª©ì„¤ëª…
                        }
                        
                        # ë¹ˆ ê°’ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                        if element['name_eng'] or element['name_kor']:
                            elements.append(element)
                            
                except Exception as e:
                    print(f"âš ï¸ ì‘ë‹µ ìš”ì†Œ í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue
            
            return elements
            
        except Exception as e:
            print(f"âš ï¸ ì¶œë ¥ê²°ê³¼ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def extract_api_info(self, swagger_json):
        """API ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ"""
        api_info = {}
        
        if not swagger_json:
            return api_info
            
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        info = swagger_json.get('info', {})
        api_info['title'] = info.get('title', '')
        api_info['description'] = info.get('description', '')
        api_info['version'] = info.get('version', '')
        
        # í™•ì¥ ì •ë³´ ì¶”ì¶œ
        if 'x-' in info:
            for key, value in info.items():
                if key.startswith('x-'):
                    api_info[key.replace('x-', '')] = value
        
        return api_info
    
    def extract_base_url(self, swagger_json):
        """Base URL ì¶”ì¶œ"""
        if not swagger_json:
            return ""
            
        schemes = swagger_json.get('schemes', ['https'])
        host = swagger_json.get('host', '')
        base_path = swagger_json.get('basePath', '')
        
        if host:
            scheme = schemes[0] if schemes else 'https'
            return f"{scheme}://{host}{base_path}"
        return ""
    
    def extract_endpoints(self, swagger_json):
        """ì—”ë“œí¬ì¸íŠ¸ ì •ë³´ ì¶”ì¶œ"""
        endpoints = []
        
        if not swagger_json:
            return endpoints
            
        paths = swagger_json.get('paths', {})
        
        for path, methods in paths.items():
            for method, data in methods.items():
                if method in ['get', 'post', 'put', 'delete', 'patch']:
                    endpoint = {
                        'method': method.upper(),
                        'path': path,
                        'description': data.get('summary', '') or data.get('description', ''),
                        'parameters': self._extract_parameters(data.get('parameters', [])),
                        'responses': self._extract_responses(data.get('responses', {})),
                        'tags': data.get('tags', []),
                        'section': data.get('tags', ['Default'])[0] if data.get('tags') else 'Default'
                    }
                    endpoints.append(endpoint)
        
        return endpoints
    
    def _extract_parameters(self, params_list):
        """íŒŒë¼ë¯¸í„° ì •ë³´ ì¶”ì¶œ"""
        parameters = []
        
        for param in params_list:
            parameters.append({
                'name': param.get('name', ''),
                'description': param.get('description', ''),
                'required': param.get('required', False),
                'type': param.get('type', '') or (param.get('schema', {}).get('type', '') if 'schema' in param else '')
            })
        
        return parameters
    
    def _extract_responses(self, responses_dict):
        """ì‘ë‹µ ì •ë³´ ì¶”ì¶œ"""
        responses = []
        
        for status_code, data in responses_dict.items():
            responses.append({
                'status_code': status_code,
                'description': data.get('description', '')
            })
        
        return responses


class DataExporter:
    """ë°ì´í„° ë‚´ë³´ë‚´ê¸° í´ë˜ìŠ¤"""
    
    @staticmethod
    def save_as_json(data, file_path):
        """JSON í˜•íƒœë¡œ ì €ì¥"""
        try:
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            dir_path = os.path.dirname(file_path)
            if dir_path:
                os.makedirs(dir_path, exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True, None
        except Exception as e:
            return False, f"JSON ì €ì¥ ì‹¤íŒ¨: {str(e)}"
    
    @staticmethod
    def dict_to_xml(data, root_name="api_documentation"):
        """ë”•ì…”ë„ˆë¦¬ë¥¼ XMLë¡œ ë³€í™˜"""
        try:
            def _dict_to_xml_element(d, parent, name=None):
                if name is None:
                    element = parent
                else:
                    # XML íƒœê·¸ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ìœ íš¨ì„± ê²€ì‚¬
                    clean_name = re.sub(r'[^a-zA-Z0-9_-]', '_', str(name))
                    # ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” íƒœê·¸ëª… ì²˜ë¦¬
                    if clean_name and clean_name[0].isdigit():
                        clean_name = f"item_{clean_name}"
                    # ë¹ˆ íƒœê·¸ëª… ì²˜ë¦¬
                    if not clean_name:
                        clean_name = "unnamed_item"
                    
                    element = SubElement(parent, clean_name)
                
                if isinstance(d, dict):
                    for key, value in d.items():
                        _dict_to_xml_element(value, element, key)
                elif isinstance(d, list):
                    for i, item in enumerate(d):
                        if isinstance(item, dict):
                            _dict_to_xml_element(item, element, f"item_{i}")
                        else:
                            item_elem = SubElement(element, f"item_{i}")
                            item_elem.text = str(item) if item is not None else ""
                else:
                    element.text = str(d) if d is not None else ""
            
            root = Element(root_name)
            _dict_to_xml_element(data, root)
            return root, None
        except Exception as e:
            return None, f"XML ë³€í™˜ ì‹¤íŒ¨: {str(e)}"
    
    @staticmethod
    def save_as_xml(data, file_path):
        """XML í˜•íƒœë¡œ ì €ì¥"""
        try:
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            dir_path = os.path.dirname(file_path)
            if dir_path:
                os.makedirs(dir_path, exist_ok=True)
            
            # ë”•ì…”ë„ˆë¦¬ë¥¼ XMLë¡œ ë³€í™˜
            root, error = DataExporter.dict_to_xml(data)
            if error:
                return False, error
            
            # ì˜ˆì˜ê²Œ í¬ë§·íŒ…
            rough_string = tostring(root, encoding='utf-8')
            reparsed = minidom.parseString(rough_string)
            pretty_xml = reparsed.toprettyxml(indent='  ', encoding='utf-8')
            
            with open(file_path, 'wb') as f:
                f.write(pretty_xml)
            
            return True, None
        except Exception as e:
            return False, f"XML ì €ì¥ ì‹¤íŒ¨: {str(e)}"
    
    @staticmethod
    def save_as_markdown(data, file_path):
        """Markdown í˜•íƒœë¡œ ì €ì¥"""
        try:
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            dir_path = os.path.dirname(file_path)
            if dir_path:
                os.makedirs(dir_path, exist_ok=True)
            
            md_content = DataExporter.dict_to_markdown(data)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            return True, None
        except Exception as e:
            return False, f"Markdown ì €ì¥ ì‹¤íŒ¨: {str(e)}"
    
    @staticmethod
    def dict_to_markdown(data):
        """ë”•ì…”ë„ˆë¦¬ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            md_lines = []
            api_type = data.get('api_type', 'unknown')
            
            # API íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            if api_type == 'swagger':
                return DataExporter._swagger_to_markdown(data, md_lines)
            elif api_type == 'general':
                return DataExporter._general_api_to_markdown(data, md_lines)
            elif api_type == 'link':
                return DataExporter._link_to_markdown(data, md_lines)
            else:
                return "# API ë¬¸ì„œ\n\nì•Œ ìˆ˜ ì—†ëŠ” API íƒ€ì…ì…ë‹ˆë‹¤."
                
        except Exception as e:
            print(f"âš ï¸ Markdown ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"# Markdown ë³€í™˜ ì˜¤ë¥˜\n\në³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    @staticmethod
    def _link_to_markdown(data, md_lines):
        """LINK íƒ€ì… APIë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
        md_lines.append("# LINK íƒ€ì… API")
        md_lines.append("")
        
        # í¬ë¡¤ë§ ì •ë³´
        if data.get('crawled_time'):
            md_lines.append(f"**í¬ë¡¤ë§ ì‹œê°„:** {data['crawled_time']}")
        if data.get('crawled_url'):
            md_lines.append(f"**ì›ë³¸ URL:** {data['crawled_url']}")
        md_lines.append("")
        
        md_lines.append("## ğŸ“‹ API ì •ë³´")
        md_lines.append("")
        md_lines.append("ì´ APIëŠ” LINK íƒ€ì…ìœ¼ë¡œ, ì™¸ë¶€ ë§í¬ë¥¼ í†µí•´ ì œê³µë©ë‹ˆë‹¤.")
        md_lines.append("")
        
        # í…Œì´ë¸” ì •ë³´
        table_info = data.get('info', {})
        if table_info:
            md_lines.append("## ğŸ“Š ìƒì„¸ ì •ë³´")
            md_lines.append("")
            for key, value in table_info.items():
                md_lines.append(f"**{key}:** {value}")
            md_lines.append("")
        
        # ê±´ë„ˆë›´ ì´ìœ 
        if data.get('skip_reason'):
            md_lines.append("## â„¹ï¸ ì²˜ë¦¬ ì •ë³´")
            md_lines.append("")
            md_lines.append(f"**ì²˜ë¦¬ ìƒíƒœ:** {data['skip_reason']}")
            md_lines.append("")
        
        # í‘¸í„°
        md_lines.append("## ğŸ“ ìƒì„± ì •ë³´")
        md_lines.append("")
        md_lines.append("ì´ ë¬¸ì„œëŠ” ë‚˜ë¼ì¥í„° API í¬ë¡¤ëŸ¬ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        md_lines.append("**API íƒ€ì…:** LINK (ì™¸ë¶€ ë§í¬ ì œê³µ)")
        if data.get('api_id'):
            md_lines.append(f"**API ID:** {data['api_id']}")
        
        return "\n".join(md_lines)   
    
    @staticmethod
    def _swagger_to_markdown(data, md_lines):
        """Swagger APIë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
        api_info = data.get('api_info', {})
        endpoints = data.get('endpoints', [])
        
        # ì œëª©
        title = api_info.get('title', 'API Documentation')
        md_lines.append(f"# {title}")
        md_lines.append("")
        
        # í¬ë¡¤ë§ ì •ë³´
        if data.get('crawled_time'):
            md_lines.append(f"**í¬ë¡¤ë§ ì‹œê°„:** {data['crawled_time']}")
        if data.get('crawled_url'):
            md_lines.append(f"**ì›ë³¸ URL:** {data['crawled_url']}")
        md_lines.append("")
        
        # API ê¸°ë³¸ ì •ë³´
        md_lines.append("## ğŸ“‹ API ì •ë³´")
        md_lines.append("")
        
        if api_info.get('description'):
            description = str(api_info['description']).replace('\n', ' ').strip()
            md_lines.append(f"**ì„¤ëª…:** {description}")
            md_lines.append("")
        
        # Base URL ì •ë³´
        if api_info.get('base_url'):
            md_lines.append(f"**Base URL:** `{api_info['base_url']}`")
            md_lines.append("")
        
        if api_info.get('schemes') and isinstance(api_info['schemes'], list):
            schemes_str = ", ".join(str(s) for s in api_info['schemes'])
            md_lines.append(f"**ì§€ì› í”„ë¡œí† ì½œ:** {schemes_str}")
            md_lines.append("")
        
        # ì—”ë“œí¬ì¸íŠ¸ ì •ë³´
        if endpoints and isinstance(endpoints, list):
            md_lines.append(f"## ğŸ”— API ì—”ë“œí¬ì¸íŠ¸ ({len(endpoints)}ê°œ)")
            md_lines.append("")
            
            # Base URLì´ ìˆìœ¼ë©´ ì™„ì „í•œ URL ì •ë³´ ì¶”ê°€
            base_url = api_info.get('base_url', '')
            if base_url:
                md_lines.append(f"**Base URL:** `{base_url}`")
                md_lines.append("")
            
            # ì„¹ì…˜ë³„ë¡œ ê·¸ë£¹í™”
            sections = {}
            for endpoint in endpoints:
                if not isinstance(endpoint, dict):
                    continue
                section = endpoint.get('section', 'Default')
                if section not in sections:
                    sections[section] = []
                sections[section].append(endpoint)
            
            for section_name, section_endpoints in sections.items():
                if len(sections) > 1:  # ì„¹ì…˜ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°ë§Œ ì„¹ì…˜ ì œëª© í‘œì‹œ
                    md_lines.append(f"### {section_name}")
                    md_lines.append("")
                
                for endpoint in section_endpoints:
                    try:
                        # ì—”ë“œí¬ì¸íŠ¸ ì œëª©
                        method = str(endpoint.get('method', 'GET')).upper()
                        path = str(endpoint.get('path', ''))
                        description = str(endpoint.get('description', '')).replace('\n', ' ').strip()
                        
                        # ì™„ì „í•œ URL ìƒì„± (Base URLì´ ìˆëŠ” ê²½ìš°)
                        full_url = f"{base_url}{path}" if base_url and path else path
                        
                        md_lines.append(f"#### `{method}` {path}")
                        if base_url:
                            md_lines.append(f"**ì™„ì „í•œ URL:** `{full_url}`")
                        md_lines.append("")
                        
                        if description:
                            md_lines.append(f"**ì„¤ëª…:** {description}")
                            md_lines.append("")
                        
                        # íŒŒë¼ë¯¸í„° ì •ë³´
                        parameters = endpoint.get('parameters', [])
                        if parameters and isinstance(parameters, list):
                            md_lines.append("**íŒŒë¼ë¯¸í„°:**")
                            md_lines.append("")
                            md_lines.append("| ì´ë¦„ | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |")
                            md_lines.append("|------|------|------|------|")
                            
                            for param in parameters:
                                if not isinstance(param, dict):
                                    continue
                                name = str(param.get('name', '')).replace('|', '\\|')
                                param_type = str(param.get('type', '')).replace('|', '\\|')
                                required = "âœ…" if param.get('required', False) else "âŒ"
                                desc = str(param.get('description', '')).replace('\n', ' ').replace('|', '\\|')
                                
                                # ì„¤ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ì¤„ì´ê¸°
                                if len(desc) > 50:
                                    desc = desc[:50] + "..."
                                
                                md_lines.append(f"| `{name}` | {param_type} | {required} | {desc} |")
                            
                            md_lines.append("")
                        
                        # ì‘ë‹µ ì •ë³´
                        responses = endpoint.get('responses', [])
                        if responses and isinstance(responses, list):
                            md_lines.append("**ì‘ë‹µ:**")
                            md_lines.append("")
                            md_lines.append("| ìƒíƒœ ì½”ë“œ | ì„¤ëª… |")
                            md_lines.append("|-----------|------|")
                            
                            for response in responses:
                                if not isinstance(response, dict):
                                    continue
                                status_code = str(response.get('status_code', '')).replace('|', '\\|')
                                desc = str(response.get('description', '')).replace('\n', ' ').replace('|', '\\|')
                                
                                # ì„¤ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ì¤„ì´ê¸°
                                if len(desc) > 80:
                                    desc = desc[:80] + "..."
                                
                                md_lines.append(f"| `{status_code}` | {desc} |")
                            
                            md_lines.append("")
                        
                        md_lines.append("---")
                        md_lines.append("")
                    except Exception as e:
                        print(f"âš ï¸ ì—”ë“œí¬ì¸íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                        continue
        
        # í‘¸í„°
        md_lines.append("## ğŸ“ ìƒì„± ì •ë³´")
        md_lines.append("")
        md_lines.append("ì´ ë¬¸ì„œëŠ” ë‚˜ë¼ì¥í„° API í¬ë¡¤ëŸ¬ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if data.get('api_id'):
            md_lines.append(f"**API ID:** {data['api_id']}")
        if api_info.get('base_url'):
            md_lines.append(f"**Base URL:** {api_info['base_url']}")
        
        return "\n".join(md_lines)
    
    @staticmethod
    def _general_api_to_markdown(data, md_lines):
        """ì¼ë°˜ APIë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
        general_info = data.get('general_api_info', {})
        detail_info = general_info.get('detail_info', {})
        
        # ì œëª©
        title = detail_info.get('description', 'API Documentation')[:50] + "..." if len(detail_info.get('description', '')) > 50 else detail_info.get('description', 'API Documentation')
        md_lines.append(f"# {title}")
        md_lines.append("")
        
        # í¬ë¡¤ë§ ì •ë³´
        if data.get('crawled_time'):
            md_lines.append(f"**í¬ë¡¤ë§ ì‹œê°„:** {data['crawled_time']}")
        if data.get('crawled_url'):
            md_lines.append(f"**ì›ë³¸ URL:** {data['crawled_url']}")
        md_lines.append("")
        
        # ìƒì„¸ê¸°ëŠ¥ ì •ë³´
        if detail_info:
            md_lines.append("## ğŸ“‹ API ìƒì„¸ì •ë³´")
            md_lines.append("")
            
            if detail_info.get('description'):
                md_lines.append(f"**ê¸°ëŠ¥ ì„¤ëª…:**")
                md_lines.append(f"{detail_info['description']}")
                md_lines.append("")
            
            if detail_info.get('request_url'):
                md_lines.append(f"**ìš”ì²­ ì£¼ì†Œ:** `{detail_info['request_url']}`")
                md_lines.append("")
            
            if detail_info.get('service_url'):
                md_lines.append(f"**ì„œë¹„ìŠ¤ URL:** `{detail_info['service_url']}`")
                md_lines.append("")
            
            # í™œìš©ìŠ¹ì¸ ì ˆì°¨
            if detail_info.get('approval_process'):
                approval = detail_info['approval_process']
                md_lines.append("**í™œìš©ìŠ¹ì¸ ì ˆì°¨:**")
                if approval.get('development'):
                    md_lines.append(f"- ê°œë°œë‹¨ê³„: {approval['development']}")
                if approval.get('operation'):
                    md_lines.append(f"- ìš´ì˜ë‹¨ê³„: {approval['operation']}")
                md_lines.append("")
            
            # ì‹ ì²­ê°€ëŠ¥ íŠ¸ë˜í”½
            if detail_info.get('traffic_limit'):
                traffic = detail_info['traffic_limit']
                md_lines.append("**ì‹ ì²­ê°€ëŠ¥ íŠ¸ë˜í”½:**")
                if traffic.get('development'):
                    md_lines.append(f"- ê°œë°œê³„ì •: {traffic['development']}")
                if traffic.get('operation'):
                    md_lines.append(f"- ìš´ì˜ê³„ì •: {traffic['operation']}")
                md_lines.append("")
        
        # ìš”ì²­ë³€ìˆ˜
        request_params = general_info.get('request_parameters', [])
        if request_params:
            md_lines.append(f"## ğŸ“¤ ìš”ì²­ë³€ìˆ˜ ({len(request_params)}ê°œ)")
            md_lines.append("")
            md_lines.append("| í•­ëª©ëª…(êµ­ë¬¸) | í•­ëª©ëª…(ì˜ë¬¸) | í¬ê¸° | í•„ìˆ˜ì—¬ë¶€ | ìƒ˜í”Œë°ì´í„° | ì„¤ëª… |")
            md_lines.append("|--------------|--------------|------|----------|------------|------|")
            
            for param in request_params:
                name_kor = str(param.get('name_kor', '')).replace('|', '\\|')
                name_eng = str(param.get('name_eng', '')).replace('|', '\\|')
                size = str(param.get('size', '')).replace('|', '\\|')
                required = str(param.get('required', '')).replace('|', '\\|')
                sample = str(param.get('sample_data', '')).replace('|', '\\|')
                desc = str(param.get('description', '')).replace('|', '\\|')
                
                # ê¸´ í…ìŠ¤íŠ¸ ì¤„ì´ê¸°
                if len(sample) > 30:
                    sample = sample[:30] + "..."
                if len(desc) > 50:
                    desc = desc[:50] + "..."
                
                md_lines.append(f"| {name_kor} | `{name_eng}` | {size} | {required} | {sample} | {desc} |")
            
            md_lines.append("")
        
        # ì¶œë ¥ê²°ê³¼
        response_elements = general_info.get('response_elements', [])
        if response_elements:
            md_lines.append(f"## ğŸ“¥ ì¶œë ¥ê²°ê³¼ ({len(response_elements)}ê°œ)")
            md_lines.append("")
            md_lines.append("| í•­ëª©ëª…(êµ­ë¬¸) | í•­ëª©ëª…(ì˜ë¬¸) | í¬ê¸° | í•„ìˆ˜ì—¬ë¶€ | ìƒ˜í”Œë°ì´í„° | ì„¤ëª… |")
            md_lines.append("|--------------|--------------|------|----------|------------|------|")
            
            for element in response_elements:
                name_kor = str(element.get('name_kor', '')).replace('|', '\\|')
                name_eng = str(element.get('name_eng', '')).replace('|', '\\|')
                size = str(element.get('size', '')).replace('|', '\\|')
                required = str(element.get('required', '')).replace('|', '\\|')
                sample = str(element.get('sample_data', '')).replace('|', '\\|')
                desc = str(element.get('description', '')).replace('|', '\\|')
                
                # ê¸´ í…ìŠ¤íŠ¸ ì¤„ì´ê¸°
                if len(sample) > 30:
                    sample = sample[:30] + "..."
                if len(desc) > 50:
                    desc = desc[:50] + "..."
                
                md_lines.append(f"| {name_kor} | `{name_eng}` | {size} | {required} | {sample} | {desc} |")
            
            md_lines.append("")
        
        # í‘¸í„°
        md_lines.append("## ğŸ“ ìƒì„± ì •ë³´")
        md_lines.append("")
        md_lines.append("ì´ ë¬¸ì„œëŠ” ë‚˜ë¼ì¥í„° API í¬ë¡¤ëŸ¬ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        md_lines.append("**API íƒ€ì…:** ì¼ë°˜ API (Swagger ë¯¸ì§€ì›)")
        if data.get('api_id'):
            md_lines.append(f"**API ID:** {data['api_id']}")
        
        return "\n".join(md_lines)
    
    @staticmethod
    def save_crawling_result(data, output_dir, api_id, formats=['json', 'xml']):
        """í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ - ê°œì„ ëœ ë¡œì§"""
        saved_files = []
        errors = []
        
        # í…Œì´ë¸” ì •ë³´ì—ì„œ ì œê³µê¸°ê´€ê³¼ ìˆ˜ì •ì¼ ì¶”ì¶œ
        table_info = data.get('info', {})
        org_name = table_info.get('ì œê³µê¸°ê´€', 'unknown_org')
        modified_date = table_info.get('ìˆ˜ì •ì¼', 'unknown_date')
        
        # URLì—ì„œ ë¬¸ì„œë²ˆí˜¸ ì¶”ì¶œ
        crawled_url = data.get('crawled_url', '')
        doc_num = 'unknown_doc'
        if crawled_url:
            match = re.search(r'/data/(\d+)/openapi\.do', crawled_url)
            if match:
                doc_num = match.group(1)
        
        # ê¸°ê´€ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
        org_name = re.sub(r'[^\w\s-]', '', org_name)
        org_name = re.sub(r'[\s]+', '_', org_name).strip()
        
        # API ìœ í˜• í™•ì¸
        api_type = data.get('api_type', 'unknown')
        api_category = table_info.get('API ìœ í˜•', '')
        is_link_type = 'LINK' in api_category.upper() if api_category else False
        
        # API ìœ í˜•ì— ë”°ë¥¸ ìƒìœ„ ë””ë ‰í† ë¦¬ ì„¤ì • (ê°œì„ ëœ ë¡œì§)
        if api_type == 'link' or is_link_type:
            # LINK íƒ€ì…ì˜ ê²½ìš°
            base_output_dir = os.path.join(output_dir, 'LINK', org_name)
            print(f"ğŸ”— LINK íƒ€ì… ì €ì¥ ê²½ë¡œ: {base_output_dir}")
        elif api_type == 'general':
            # ì¼ë°˜ API (Swagger ë¯¸ì§€ì›)ì˜ ê²½ìš°
            base_output_dir = os.path.join(output_dir, 'ì¼ë°˜API_old', org_name)
            print(f"ğŸ“‹ ì¼ë°˜ API ì €ì¥ ê²½ë¡œ: {base_output_dir}")
        elif api_type == 'swagger':
            # Swagger APIì˜ ê²½ìš°
            base_output_dir = os.path.join(output_dir, 'ì¼ë°˜API', org_name)
            print(f"ğŸ”§ Swagger API ì €ì¥ ê²½ë¡œ: {base_output_dir}")
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…
            base_output_dir = os.path.join(output_dir, 'ê¸°íƒ€', org_name)
            print(f"â“ ê¸°íƒ€ íƒ€ì… ì €ì¥ ê²½ë¡œ: {base_output_dir}")
        
        # íŒŒì¼ëª… ìƒì„±
        file_prefix = f"{doc_num}_{modified_date}"
        
        os.makedirs(base_output_dir, exist_ok=True)
        
        # ê° í˜•ì‹ë³„ë¡œ ì €ì¥
        for format_type in formats:
            try:
                if format_type == 'json':
                    file_path = os.path.join(base_output_dir, f"{file_prefix}.json")
                    success, error = DataExporter.save_as_json(data, file_path)
                    if success:
                        saved_files.append(file_path)
                        print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {file_path}")
                    else:
                        errors.append(error)
                
                elif format_type == 'xml':
                    file_path = os.path.join(base_output_dir, f"{file_prefix}.xml")
                    success, error = DataExporter.save_as_xml(data, file_path)
                    if success:
                        saved_files.append(file_path)
                        print(f"âœ… XML ì €ì¥ ì™„ë£Œ: {file_path}")
                    else:
                        errors.append(error)
                
                elif format_type == 'md':
                    file_path = os.path.join(base_output_dir, f"{file_prefix}.md")
                    success, error = DataExporter.save_as_markdown(data, file_path)
                    if success:
                        saved_files.append(file_path)
                        print(f"âœ… Markdown ì €ì¥ ì™„ë£Œ: {file_path}")
                    else:
                        errors.append(error)
            
            except Exception as e:
                error_msg = f"{format_type.upper()} ì €ì¥ ì‹¤íŒ¨: {str(e)}"
                print(f"âŒ {error_msg}")
                errors.append(error_msg)
        
        return saved_files, errors
    
    @staticmethod
    def save_table_info(data, output_dir, api_id):
        """í…Œì´ë¸” ì •ë³´ ì €ì¥"""
        try:
            # info ë””ë ‰í† ë¦¬ ìƒì„±
            info_dir = os.path.join(output_dir, 'info')
            os.makedirs(info_dir, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„±
            file_name = f"{api_id}_table_info.json"
            file_path = os.path.join(info_dir, file_name)
            
            # JSONìœ¼ë¡œ ì €ì¥
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            return True, file_path
            
        except Exception as e:
            return False, f"í…Œì´ë¸” ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {str(e)}"